# Qwen3微调实战：医疗R1推理风格聊天

[English](README_EN.md)

[![](https://raw.githubusercontent.com/SwanHubX/assets/main/badge1.svg)](https://swanlab.cn/@ZeyiLin/qwen3-sft-medical/overview)

- **基础模型**：[Qwen3-0.6B](https://modelscope.cn/models/Qwen/Qwen3-0.6B/summary)
- **微调后模型**：[Qwen3-1.7b-Medical-R1-sft](https://modelscope.cn/models/testUser/Qwen3-1.7b-Medical-R1-sft/summary)
- **数据集**：[delicate_medical_r1_data](https://modelscope.cn/datasets/krisfu/delicate_medical_r1_data)
- **SwanLab**：[qwen3-sft-medical](https://swanlab.cn/@ZeyiLin/qwen3-sft-medical/runs/agps0dkifth5l1xytcdyk/chart)
- **微调方式**：全参数微调、LoRA微调
- **推理风格**：R1推理风格
- **算力要求**：
  - **全参数微调**：8GB显存
  - **LoRA微调**：6GB显存

> 为了降低显存需求，使用的是Qwen3-0.6B模型。

## 📊 模型评估结果

### 定量评估对比

#### 全参数微调 vs 基础模型
| 评估指标 | 基础模型 | 全参数微调模型 | 提升幅度 |
|---------|---------|--------------|---------|
| **困惑度** | 1.8568 | 1.8441 | **降低0.0127** |
| **BLEU分数** | 0.1154 | 0.1869 | **提升61.87%** |
| **ROUGE-1 F1** | 0.0563 | 0.0952 | **提升68.92%** |
| **词汇F1** | 0.4487 | 0.5427 | **提升20.94%** |
| **精确率** | 0.4921 | 0.5922 | **提升20.33%** |
| **召回率** | 0.4174 | 0.5094 | **提升22.04%** |

#### LoRA微调 vs 基础模型
| 评估指标 | 基础模型 | LoRA微调模型 | 提升幅度 |
|---------|---------|-------------|---------|
| **困惑度** | 1.9060 | 2.0242 | 增加6.20% |
| **BLEU分数** | 0.1235 | 0.1539 | **提升24.63%** |
| **ROUGE-1 F1** | 0.0538 | 0.0847 | **提升57.43%** |
| **词汇F1** | 0.4470 | 0.4902 | **提升9.67%** |
| **精确率** | 0.4995 | 0.5940 | **提升18.92%** |
| **召回率** | 0.4091 | 0.4314 | **提升5.45%** |

> **关键发现**：全参数微调在几乎所有评估指标上均优于LoRA微调，特别是在文本生成质量（BLEU、ROUGE）方面提升显著。

### 定性评估示例

#### 示例1：超声内镜在胃癌诊断中的作用
**问题**：医生，我听说超声内镜对胃癌的诊断很有帮助，它具体能起到什么作用呢？

**基础模型回答**：
- 包含思考过程：思考了超声内镜的基本功能，但部分描述不够准确
- 回答结构：分点列出增强诊断准确性、定位与活检等4个作用
- 准确性：部分描述存在医学概念混淆

**全参数微调模型回答**：
- 思考过程：更专业的医学推理，考虑了超声内镜在胃癌分期中的具体应用
- 回答重点：准确描述了超声内镜在肿瘤侵犯深度判断、淋巴结转移评估等关键作用
- 专业性：使用正确的医学术语，解释更符合临床实践

#### 示例2：支气管扩张症检查方法
**问题**：医生，我最近总是感觉呼吸不畅，有时候还会咳出黄色的痰，想了解一下支气管扩张症的检查方法有哪些？

**基础模型回答**：
- 误将支气管扩张症诊断为支气管哮喘
- 检查方法罗列不够准确，包含不相关的心电图检查
- 缺少对痰液检查等关键诊断方法的详细说明

**全参数微调模型回答**：
- 正确识别支气管扩张症及相关症状
- 全面列出影像学检查（胸部X线、高分辨CT）、实验室检查、微生物学检查等正确方法
- 详细说明各项检查的临床意义和诊断价值

## 项目结构

```
qwenMedSft/
├── dataset/                    # 数据集目录
│   ├── train.jsonl
│   └── val.jsonl
├── output/                    # 训练输出的模型
│   ├── Qwen3-0.6B/            # LoRA微调模型
│   │   ├── checkpoint-400
│   │   ├── checkpoint-800
│   │   └── checkpoint-1082
│   ├── Qwen3-param/           # 全参数微调模型
│   │   ├── checkpoint-400
│   │   ├── checkpoint-800
│   │   └── checkpoint-1082
├── Qwen3-0.6B/               # 基础模型
├── results/                  # 实验结果文件
│   ├── model_comparison_results.json          # LoRA微调对比结果
│   └── full_param_model_comparison_results.json  # 全参数微调对比结果
├── src/                      # 源代码
│   ├── data.py               # 数据加载和分割
│   ├── train_lora.py         # LoRA微调训练
│   ├── train.py              # 全参数微调训练
│   ├── model_compare.py      # LoRA模型对比评估
│   ├── compare_param.py      # 全参数模型对比评估
│   └── infer.py              # 三个模型对比推理
├── scripts/
│   └── run.sh                # 实验运行脚本
├── requirements.txt          # Python依赖包
└── README.md                 # 项目说明文档
```

## 安装环境

```bash
pip install -r requirements.txt
```

## 数据准备

自动完成数据集下载、预处理、验证集划分，生成`train.jsonl`和`val.jsonl`文件：

```bash
python src/data.py
```

## 训练

### 全参数微调
```bash
python src/train.py
```

### LoRA微调
```bash
python src/train_lora.py
```

### SwanLab训练日志
[![](https://raw.githubusercontent.com/SwanHubX/assets/main/badge1.svg)](https://swanlab.cn/@ZeyiLin/qwen3-sft-medical/overview)

两种微调方式对比，经测试全参数微调效果好于LoRA：

![](./readme_images/charts.png)

## 模型评估

### LoRA微调模型评估
```bash
python src/model_compare.py
```
结果保存至：`results/model_comparison_results.json`

### 全参数微调模型评估
```bash
python src/compare_param.py
```
结果保存至：`results/full_param_model_comparison_results.json`

### 评估指标说明
1. **困惑度（Perplexity）**：衡量模型预测能力，值越低越好
2. **BLEU分数**：评估生成文本与参考文本的相似度
3. **ROUGE分数**：衡量召回率导向的文本相似度
4. **F1/精确率/召回率**：基于词汇重叠的文本匹配度评估

## 推理测试

### 三个模型对比推理
```bash
python src/infer.py
```

### LoRA微调模型单次推理
```bash
python src/test_lora.py
```

### 全参数微调模型单次推理
```bash
python src/test_param.py
```

## 自动化实验脚本

本项目提供了完整的自动化实验脚本，支持一键运行整个微调实验流程。

### 快速开始
```bash
# 赋予执行权限
chmod +x scripts/run.sh

# 运行完整实验流程

./scripts/run.sh --all
```

## 训练效果示例

**问题**：医生，我最近胃部不适，听说有几种抗溃疡药物可以治疗，您能详细介绍一下这些药物的分类、作用机制以及它们是如何影响胃黏膜的保护与损伤平衡的吗？

**模型回答（含思考过程）**：
```xml
<think>
用户问的是抗溃疡药物的分类、作用机制，以及它们如何影响胃黏膜的保护和损伤平衡。
首先，我需要回忆抗溃疡药物的主要分类。主要分为几大类：抑酸药、胃黏膜保护剂、促胃动力药和抗幽门螺杆菌药物。
抑酸药包括H2受体拮抗剂和质子泵抑制剂，作用机制是抑制胃酸分泌。胃黏膜保护剂如硫糖铝、铋剂，通过形成保护层或促进黏液分泌来保护黏膜。促胃动力药通过增强胃蠕动减少反流。抗幽门螺杆菌药物通过抑制细菌生长和减少胃酸分泌来治疗溃疡。
这些药物通过不同机制平衡胃黏膜的保护和损伤：抑酸药减少损伤因素，保护剂增强防御，促胃动力药减少反流损伤，抗幽门螺杆菌药物消除病原体。
</think>

当然可以。抗溃疡药物主要分为四类：抑酸药、胃黏膜保护剂、促胃动力药和抗幽门螺杆菌药物。
1. **抑酸药**：包括H₂受体拮抗剂和质子泵抑制剂，通过抑制胃酸分泌减少对胃黏膜的化学损伤。
2. **胃黏膜保护剂**：如硫糖铝和胶体果胶铋，在胃黏膜表面形成保护膜，隔离胃酸和胃蛋白酶的侵蚀。
3. **促胃动力药**：如多潘立酮，增强胃排空，减少胃内食物和胃酸的反流时间。
4. **抗幽门螺杆菌药物**：通常采用抗生素联合质子泵抑制剂，根除幽门螺杆菌感染，消除主要病因。
这些药物共同作用，通过减少攻击因素（胃酸、幽门螺杆菌）和增强防御因素（黏膜屏障、胃排空）来恢复胃黏膜的保护与损伤平衡。
```

## 技术要点

### R1推理风格
- 模型在回答前会生成`<think>`思考过程
- 思考过程展示模型的推理逻辑和知识检索过程
- 最终回答基于思考过程的总结和提炼

### 微调策略对比
1. **全参数微调**：
   - 更新所有模型参数
   - 训练成本较高，但效果更好
   - 更适合专业领域知识学习

2. **LoRA微调**：
   - 仅训练低秩适配器
   - 训练效率高，显存需求低
   - 适合资源受限场景

### 评估方法
- 使用50个随机样本进行定量评估
- 包含5个详细样本的定性分析
- 综合多个NLP评估指标

## 相关工具

- [swanlab](https://github.com/SwanHubX/SwanLab)：开源、现代化设计的深度学习训练跟踪与可视化工具
- [transformers](https://github.com/huggingface/transformers)：HuggingFace推出的包含预训练文本、计算机视觉、音频、视频和多模态模型的库，用于推理和训练
- [peft](https://github.com/huggingface/peft)：用于高效微调大型语言模型的库

## 结论

本项目展示了在医学领域对Qwen3模型进行微调的有效性。通过对比全参数微调和LoRA微调两种方法，发现：
1. 全参数微调在医学专业问答上表现更优
2. R1推理风格能有效提升回答的专业性和可解释性
3. 在有限的0.6B参数规模下，模型仍能学习到专业的医学知识

未来可进一步探索更大参数规模的模型微调，以及更多样化的医学数据集训练。